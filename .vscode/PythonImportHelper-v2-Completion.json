[
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "site",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "site",
        "description": "site",
        "detail": "site",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "asyncio",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "asyncio",
        "description": "asyncio",
        "detail": "asyncio",
        "documentation": {}
    },
    {
        "label": "LLMChain",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "LLMChain",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "OpenAIModerationChain",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "LLMChain",
        "importPath": "langchain.chains",
        "description": "langchain.chains",
        "isExtraImport": true,
        "detail": "langchain.chains",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "ChatOpenAI",
        "importPath": "langchain.chat_models",
        "description": "langchain.chat_models",
        "isExtraImport": true,
        "detail": "langchain.chat_models",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "PromptTemplate",
        "importPath": "langchain.prompts",
        "description": "langchain.prompts",
        "isExtraImport": true,
        "detail": "langchain.prompts",
        "documentation": {}
    },
    {
        "label": "HumanMessagePromptTemplate",
        "importPath": "langchain.prompts.chat",
        "description": "langchain.prompts.chat",
        "isExtraImport": true,
        "detail": "langchain.prompts.chat",
        "documentation": {}
    },
    {
        "label": "SystemMessagePromptTemplate",
        "importPath": "langchain.prompts.chat",
        "description": "langchain.prompts.chat",
        "isExtraImport": true,
        "detail": "langchain.prompts.chat",
        "documentation": {}
    },
    {
        "label": "ChatPromptTemplate",
        "importPath": "langchain.prompts.chat",
        "description": "langchain.prompts.chat",
        "isExtraImport": true,
        "detail": "langchain.prompts.chat",
        "documentation": {}
    },
    {
        "label": "AIMessagePromptTemplate",
        "importPath": "langchain.prompts.chat",
        "description": "langchain.prompts.chat",
        "isExtraImport": true,
        "detail": "langchain.prompts.chat",
        "documentation": {}
    },
    {
        "label": "HumanMessagePromptTemplate",
        "importPath": "langchain.prompts.chat",
        "description": "langchain.prompts.chat",
        "isExtraImport": true,
        "detail": "langchain.prompts.chat",
        "documentation": {}
    },
    {
        "label": "Message",
        "importPath": "message",
        "description": "message",
        "isExtraImport": true,
        "detail": "message",
        "documentation": {}
    },
    {
        "label": "Message",
        "importPath": "message",
        "description": "message",
        "isExtraImport": true,
        "detail": "message",
        "documentation": {}
    },
    {
        "label": "Message",
        "importPath": "message",
        "description": "message",
        "isExtraImport": true,
        "detail": "message",
        "documentation": {}
    },
    {
        "label": "truncate_text",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "scold",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "truncate_text",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "tokenize_text",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "escape_prompt_content",
        "importPath": "utils",
        "description": "utils",
        "isExtraImport": true,
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "List",
        "importPath": "typing",
        "description": "typing",
        "isExtraImport": true,
        "detail": "typing",
        "documentation": {}
    },
    {
        "label": "sqlite3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sqlite3",
        "description": "sqlite3",
        "detail": "sqlite3",
        "documentation": {}
    },
    {
        "label": "faiss",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "faiss",
        "description": "faiss",
        "detail": "faiss",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "OpenAIEmbeddings",
        "importPath": "langchain.embeddings.openai",
        "description": "langchain.embeddings.openai",
        "isExtraImport": true,
        "detail": "langchain.embeddings.openai",
        "documentation": {}
    },
    {
        "label": "Repository",
        "importPath": "repository",
        "description": "repository",
        "isExtraImport": true,
        "detail": "repository",
        "documentation": {}
    },
    {
        "label": "Repository",
        "importPath": "repository",
        "description": "repository",
        "isExtraImport": true,
        "detail": "repository",
        "documentation": {}
    },
    {
        "label": "DocumentIndex",
        "importPath": "document_index",
        "description": "document_index",
        "isExtraImport": true,
        "detail": "document_index",
        "documentation": {}
    },
    {
        "label": "pprint",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pprint",
        "description": "pprint",
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "discord",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "discord",
        "description": "discord",
        "detail": "discord",
        "documentation": {}
    },
    {
        "label": "DMChannel",
        "importPath": "discord",
        "description": "discord",
        "isExtraImport": true,
        "detail": "discord",
        "documentation": {}
    },
    {
        "label": "TextChannel",
        "importPath": "discord",
        "description": "discord",
        "isExtraImport": true,
        "detail": "discord",
        "documentation": {}
    },
    {
        "label": "Conversation",
        "importPath": "conversation",
        "description": "conversation",
        "isExtraImport": true,
        "detail": "conversation",
        "documentation": {}
    },
    {
        "label": "Conversation",
        "importPath": "conversation",
        "description": "conversation",
        "isExtraImport": true,
        "detail": "conversation",
        "documentation": {}
    },
    {
        "label": "Memory",
        "importPath": "memory",
        "description": "memory",
        "isExtraImport": true,
        "detail": "memory",
        "documentation": {}
    },
    {
        "label": "tiktoken",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tiktoken",
        "description": "tiktoken",
        "detail": "tiktoken",
        "documentation": {}
    },
    {
        "label": "bin_dir",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "bin_dir = os.path.dirname(abs_file)\nbase = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "base",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "base = bin_dir[: -len(\"bin\") - 1]  # strip away the bin part from the __file__, plus the path separator\n# prepend bin to PATH (this file is inside the bin directory)\nos.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"PATH\"]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "os.environ[\"PATH\"] = os.pathsep.join([bin_dir] + os.environ.get(\"PATH\", \"\").split(os.pathsep))\nos.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "os.environ[\"VIRTUAL_ENV\"]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "os.environ[\"VIRTUAL_ENV\"] = base  # virtual env is right above bin directory\n# add the virtual environments libraries to the host python import mechanism\nprev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "prev_length",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "prev_length = len(sys.path)\nfor lib in \"../lib/python3.11/site-packages\".split(os.pathsep):\n    path = os.path.realpath(os.path.join(bin_dir, lib))\n    site.addsitedir(path.decode(\"utf-8\") if \"\" else path)\nsys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.path[:]",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]\nsys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.real_prefix",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.real_prefix = sys.prefix\nsys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "sys.prefix",
        "kind": 5,
        "importPath": ".venv.bin.activate_this",
        "description": ".venv.bin.activate_this",
        "peekOfCode": "sys.prefix = base",
        "detail": ".venv.bin.activate_this",
        "documentation": {}
    },
    {
        "label": "version_pattern",
        "kind": 5,
        "importPath": ".venv.bin.publish",
        "description": ".venv.bin.publish",
        "peekOfCode": "version_pattern = r'\\d\\.\\d\\.\\d'\nparser = argparse.ArgumentParser()\nparser.add_argument('version', help='a SEMVER string X.Y.Z')\nargs = parser.parse_args()\nif not re.match(version_pattern, args.version):\n    print('argument must be SEMVER string in format X.Y.Z')\nelse:\n    with open('setup.py') as fp:\n        old_setupfile = fp.read()\n    new_setupfile = re.sub(f\"version='{version_pattern}'\",",
        "detail": ".venv.bin.publish",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": ".venv.bin.publish",
        "description": ".venv.bin.publish",
        "peekOfCode": "parser = argparse.ArgumentParser()\nparser.add_argument('version', help='a SEMVER string X.Y.Z')\nargs = parser.parse_args()\nif not re.match(version_pattern, args.version):\n    print('argument must be SEMVER string in format X.Y.Z')\nelse:\n    with open('setup.py') as fp:\n        old_setupfile = fp.read()\n    new_setupfile = re.sub(f\"version='{version_pattern}'\",\n                           f\"version='{args.version}'\", old_setupfile)",
        "detail": ".venv.bin.publish",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": ".venv.bin.publish",
        "description": ".venv.bin.publish",
        "peekOfCode": "args = parser.parse_args()\nif not re.match(version_pattern, args.version):\n    print('argument must be SEMVER string in format X.Y.Z')\nelse:\n    with open('setup.py') as fp:\n        old_setupfile = fp.read()\n    new_setupfile = re.sub(f\"version='{version_pattern}'\",\n                           f\"version='{args.version}'\", old_setupfile)\n    with open('setup.py', 'w') as fp:\n        print(new_setupfile, file=fp)",
        "detail": ".venv.bin.publish",
        "documentation": {}
    },
    {
        "label": "Conversation",
        "kind": 6,
        "importPath": "conversation",
        "description": "conversation",
        "peekOfCode": "class Conversation:\n    TOKEN_WINDOW_SIZE = 500\n    SUMMARY_WINDOW_SIZE = 15\n    SUMMARIZER_PROMPT_TEMPLATE = \"\"\"Summarize the lines of a discord chat you've been provided as succinctly as possible.\nIt's critical that your response be formatted as a csv, otherwise it will not be accepted.\nEXAMPLE:\nLines:\nbobjones#1234: I'm asking for rice\nalice#1111: I'm hungry too, I want rice\nalvin#4321: AI make me a song",
        "detail": "conversation",
        "documentation": {}
    },
    {
        "label": "DocumentIndex",
        "kind": 6,
        "importPath": "document_index",
        "description": "document_index",
        "peekOfCode": "class DocumentIndex:\n    INDEX_WINDOW = 10\n    TEXT_EMBEDDING_ADA_002_DIMENSION = 1536\n    def __init__(self, channel_id):\n        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n        self.index = None\n        self.channel_id = channel_id\n        self.repository = Repository(channel_id)\n    def add_message(self, message, unix_timestamp):\n        if self.index is None:",
        "detail": "document_index",
        "documentation": {}
    },
    {
        "label": "index",
        "kind": 5,
        "importPath": "embedding_tester",
        "description": "embedding_tester",
        "peekOfCode": "index = DocumentIndex(1234)\n#index.add_message('Bob says hello, AI responds hi', 1234)\nprint(index.search_index('Bob says hello, AI responds hi'))",
        "detail": "embedding_tester",
        "documentation": {}
    },
    {
        "label": "clean_up_response",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def clean_up_response(discord_name, original_response):\n    if original_response.startswith(discord_name + \":\"):\n        original_response = original_response[len(discord_name + \":\"):]\n    elif original_response.startswith(\"AI:\"):\n        original_response = original_response[len(\"AI:\"):]\n    return original_response.strip()\nasync def run_chain(channel, chain, discord_context, conversation_context, long_term_memory):\n    response = await chain.arun(\n        discord_name=DISCORD_NAME,\n        discord_context=discord_context,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "get_chat_llm",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_chat_llm(temperature=0.9, max_tokens=500, gpt_version=3):\n    if gpt_version == 4:\n        chat_llm = ChatOpenAI(temperature=temperature, max_tokens=max_tokens, model='gpt-4')\n    else:\n        chat_llm = ChatOpenAI(temperature=temperature, max_tokens=max_tokens)\n    return chat_llm\ndiscord_bot_key = os.environ['DISCORD_BOT_TOKEN']\nintents = discord.Intents.default()\nintents.message_content = True\npaused = False",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "DISCORD_NAME",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "DISCORD_NAME = 'EhrlichGPT'\ndef clean_up_response(discord_name, original_response):\n    if original_response.startswith(discord_name + \":\"):\n        original_response = original_response[len(discord_name + \":\"):]\n    elif original_response.startswith(\"AI:\"):\n        original_response = original_response[len(\"AI:\"):]\n    return original_response.strip()\nasync def run_chain(channel, chain, discord_context, conversation_context, long_term_memory):\n    response = await chain.arun(\n        discord_name=DISCORD_NAME,",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "discord_bot_key",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "discord_bot_key = os.environ['DISCORD_BOT_TOKEN']\nintents = discord.Intents.default()\nintents.message_content = True\npaused = False\n# TODO: Make this configurable\nadmin = 'adotout#7295'\nclient = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "intents",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "intents = discord.Intents.default()\nintents.message_content = True\npaused = False\n# TODO: Make this configurable\nadmin = 'adotout#7295'\nclient = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "intents.message_content",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "intents.message_content = True\npaused = False\n# TODO: Make this configurable\nadmin = 'adotout#7295'\nclient = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "paused",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "paused = False\n# TODO: Make this configurable\nadmin = 'adotout#7295'\nclient = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "admin",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "admin = 'adotout#7295'\nclient = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')\n    for db_file in os.listdir(\"conversations\"):\n        if db_file == \".gitignore\":",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "client = discord.Client(intents=intents)\nconversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')\n    for db_file in os.listdir(\"conversations\"):\n        if db_file == \".gitignore\":\n            continue",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "conversations",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "conversations = {}\nchat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')\n    for db_file in os.listdir(\"conversations\"):\n        if db_file == \".gitignore\":\n            continue\n        channel_db = os.path.splitext(db_file)[0]",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "chat",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "chat = ChatOpenAI(temperature=0.9, max_tokens=500)\nos.makedirs(\"conversations\", exist_ok=True)\n@client.event\nasync def on_ready():\n    print(f'We have logged in as {client.user}')\n    for db_file in os.listdir(\"conversations\"):\n        if db_file == \".gitignore\":\n            continue\n        channel_db = os.path.splitext(db_file)[0]\n        channel_id = int(channel_db.split('.')[0])",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "Memory",
        "kind": 6,
        "importPath": "memory",
        "description": "memory",
        "peekOfCode": "class Memory:\n    def __init__(self, id, memory_text, unix_timestamp, serialized_embedding):\n        self.id = id\n        self.memory_text = memory_text\n        self.unix_timestamp = unix_timestamp\n        self.serialized_embedding = serialized_embedding\n        self.text_token_count = -1\n    # Function that gets the token count of memory_text\n    def get_token_count(self):\n        if self.text_token_count == -1:",
        "detail": "memory",
        "documentation": {}
    },
    {
        "label": "Message",
        "kind": 6,
        "importPath": "message",
        "description": "message",
        "peekOfCode": "class Message:\n    CENSORED = '[Text removed due to content policy violation]'\n    def __init__(self, sender, content, gpt_version_requested=3, at_mentioned=False):\n        self.sender = sender\n        self.content = content\n        self.token_count = 0\n        self.gpt_version_requested = gpt_version_requested\n        self.at_mentioned = at_mentioned\n    def get_prompt_template(self):\n        if self.sender == \"ai\":",
        "detail": "message",
        "documentation": {}
    },
    {
        "label": "Repository",
        "kind": 6,
        "importPath": "repository",
        "description": "repository",
        "peekOfCode": "class Repository:\n    def __init__(self, channel_id: int) -> None:\n        self.db_path = self.__get_db_path(channel_id)\n        self.__create_db_if_not_exists()\n    def clear_messages(self) -> None:\n        conn = sqlite3.connect(self.db_path)\n        conn.execute(\"DELETE FROM messages\")\n        conn.commit()\n        conn.close()\n    def save_message(self, sender, content):",
        "detail": "repository",
        "documentation": {}
    },
    {
        "label": "escape_prompt_content",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def escape_prompt_content(content: str) -> str:\n    return content.replace('{', '{{').replace('}', '}}')\ndef truncate_text(text: str, n_tokens: int, direction: int=1) -> str:\n    if n_tokens < 1:\n        raise ValueError(\"n_tokens must be greater than 0\")\n    # Split the text into tokens\n    tokens = tokenize_text(text)\n    print(len(tokens))\n    # Keep the first N tokens and join them\n    if direction > 0:",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "truncate_text",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def truncate_text(text: str, n_tokens: int, direction: int=1) -> str:\n    if n_tokens < 1:\n        raise ValueError(\"n_tokens must be greater than 0\")\n    # Split the text into tokens\n    tokens = tokenize_text(text)\n    print(len(tokens))\n    # Keep the first N tokens and join them\n    if direction > 0:\n        truncated_tokens = tokens[:n_tokens]\n    else:",
        "detail": "utils",
        "documentation": {}
    },
    {
        "label": "tokenize_text",
        "kind": 2,
        "importPath": "utils",
        "description": "utils",
        "peekOfCode": "def tokenize_text(text: str) -> list:\n    tokenizer = tiktoken.get_encoding('gpt2')\n    tokens = tokenizer.encode(text)\n    return [tokenizer.decode([token]) for token in tokens]\nasync def scold() -> str:\n    feelings_list = [\n        \"sadness\",\n        \"angry\",\n        \"fear\",\n        \"surprise\",",
        "detail": "utils",
        "documentation": {}
    }
]